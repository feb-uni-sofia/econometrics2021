---
title: "Week 5"
author: "Boyko Amarov"
date: "4/19/2021"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(broom)
## install.packages("broom")
kids <- read_csv("https://raw.githubusercontent.com/feb-uni-sofia/econometrics2020-solutions/master/data/childiq.csv") %>% select(kid_score, mom_hs)
```

## Lineares Regressionsmodell mit einem kategoriallen Prädiktor 

Variablenbeschreibung:

- `kid_score`: (numeric) Punkte vom IQ Test.
- `mom_hs` (binary): 1 Mutter hat Abitur, 0 Mutter hat keine Abitur

Frage:
Gibt es Unterschiede zwischen den Intelligenztestergebnissen von Kindern mit Müttern mit/ohne Abitur.

Vorschlag: wir spalten den Datensatz nach Gruppenzugehörigkeit (mit/ohne Abitur) und vergleichen die Gruppen 
z.B. anhand des Mittelwertes der Testergebnisse.


```{r}
## == (logischer Vergleich)
kids_mom_nohs <- kids %>% filter(mom_hs == 0)
kids_mom_hs <- kids %>% filter(mom_hs == 1)
```


```{r}
summary(kids_mom_nohs$kid_score)
summary(kids_mom_hs$kid_score)
```

```{r}
# ggplot(data = kids, aes(x = mom_hs, y = kid_score, color = factor(mom_hs))) + 
#   geom_point(position = "jitter")
ggplot(data = kids, aes(x = mom_hs, y = kid_score, colour = factor(mom_hs))) +
  geom_point(position = "jitter") + 
  labs(
    x = "Gruppenzugehörigkeit (ohne Abitur/mit Abitur)",
    y = "Erzielte Punktzahl"
  )
```

```{r}
# ggplot(data = kids, aes(x = mom_hs, y = kid_score, color = factor(mom_hs))) + 
#   geom_point(position = "jitter")
ggplot(data = kids, aes(x = mom_hs, y = kid_score, colour = factor(mom_hs))) +
  geom_point(position = "jitter") + 
  labs(
    x = "Gruppenzugehörigkeit (ohne Abitur/mit Abitur)",
    y = "Erzielte Punktzahl"
  )
```

```{r}
ggplot(data = kids, aes(x = kid_score, y = factor(mom_hs))) + 
  geom_boxplot()
```

$$
i = 1,\ldots,n = 434 \text{ Kinder}\\
y_i: \text{ Testergebnis von Kind } i\\
x_i: \text{ Gruppenzugehörigkeit von Kind (1: Mutter mit Abitur/0: Mutter ohne Abitur) } i\\
$$
$$
y_i = \alpha + \beta x_i + e_i, \quad E(e_i) = 0, i = 1,\ldots,n
$$
$$
E(y_i) = \alpha + \beta x_i\\
\begin{align}
E(y_i) = 
\begin{cases} 
\mu_1 = \alpha + \beta & \text{falls } x_i = 1 \text{ Erwartetes Testergebnis für die Gruppe mit Abitur (der Mutter)} \\
\mu_0 = \alpha & \text{falls } x_i = 0 \text{ Erwartetes Testergebnis für die Gruppe ohne Abitur (der Mutter)}
\end{cases}   
\end{align}\\
\implies\\
\beta = \mu_1 - \mu_0
$$
$\alpha$ ist einfach das erwartete Testergebnis für die Gruppe ohne Abitur (der Mutter). $\beta$ ist einfach die Differenz zwischen den erwarteten Testergebnissen der zwei Gruppen.


```{r}
lm(kid_score ~ 1 + mom_hs, data = kids)
```

$$
\hat{\alpha} = 77.55 \text{ Mitterwert der Testergebnise in der Gruppe ohne Abitur (Mutter)}\\
\hat{\beta} = 11.77 = 89.32 - 77.55 \text{ Differenz der zwei Gruppenmitterwerte} \\
\hat{y}_i =  \hat{\alpha} + \hat{\beta} x_i\\
\hat{y}_i = 77.55 + 11.77 x_i \text{ geschätzte Gleichung}
$$

Das geschätzte Testergebnis von Kindern (Mutter ohne Abitur, $x = 0$) is gleich 77.55 (Punkte). Das geschätzte Testergebnis von Kindern (Mutter mit Abitur, $x = 1$) is um 11.77 Punkte höher als das erwartete Testregebnis der anderen Groupe (Mutter ohne Abitur, $x = 0$).

$$
89.32 - 77.55 = 11.77
$$
## Normalverteilung


### Bedeuting der Parameter der Normalverteilung

Die Dichtefunktion der Normalverteilung mit Parametern $\mu$ und $\sigma$ ist gegeben durch:
$$
f(x) = \frac{1}{\sqrt{\pi \sigma^2}}e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}, \quad y \in R
$$


wir schreiben $N(\mu, \sigma^2)$. Die Normalverteilung mit Erwartungswert $\mu = 0$ und Standardabweichung $\sigma = 1$ nennen wir die Standardnormalverteilung N(0, 1).

```{r}
## d(density)norm(normal distribution)
## Wert der Dichtefunktion der Normalverteilung mit mu = 0, sigma = 1: N(0, 1)
?dnorm
dnorm(x = 0, mean = 0, sd = 1)

## Wert der Dichtefunktion mit mu = 5, sigma = 2: N(0, 4)
dnorm(x = 1, mean = 5, sd = 2)
```


Graphische Darstellung der Dichtefunktion (Vorbereitung der Daten)

```{r}
norm_df <- expand_grid(
  x = seq(-5, 5, length.out = 300),
  mu = c(0, 1),
  sigma = c(1, 2)
) %>%
  mutate(
    y = dnorm(x, mean = mu, sd = sigma)
  )
```

Graphische Darstellung der Dichtefunktion (Graphik zeichnen)

```{r}
norm_df %>%
  ggplot(aes(x = x, y = y, colour = factor(mu), lty = factor(sigma))) +
  geom_line()

## lty: line type
```
### Berechnung von Wahrscheinlichkeiten (Normalverteilung)


<!-- The area under the density over an interval equals the probability of an event occurring in the interval. -->

<!-- We take the standard normal distribution N(0, 1) and want to compute the probability of x occurring between -1 and 1. -->




```{r}
d <- data.frame(
  x = seq(-5, 5, length.out = 200)
) %>%
  mutate(
    ## Dnorm computes the density 
    y = dnorm(x, mean = 0, sd = 1)
  )

std_norm_plot <- d %>% 
  ggplot(aes(x = x)) +
  # note this next line is the only difference in code from the last plot
  geom_ribbon(
    data = d %>% filter(x > -1, x < 1),
    aes(ymin = 0, ymax = y), fill = "gray"
  ) +
  geom_line(aes(y = y)) +
  annotate(geom = "text", x = 0, y = 0.2, label = expression("p" %~~% "0.682")) +
  labs(
    x = "x",
    y = "Normal density"
  ) +
  geom_vline(xintercept = -1, lty = 2) + 
  geom_vline(xintercept = 1, lty = 2)

plot(std_norm_plot)
```
```{r}
## p(probability/Wahrscheinlichkeit)norm(normal distribution)
pnorm(-1, mean = 0, sd = 1)
```

$$
P(x < -1|\mu = 0, \sigma = 1) = 0.1586553
$$


```{r}
## p(probability)norm(normal distribution)
pnorm(1, mean = 0, sd = 1)
```

$$
P(x < 1|\mu = 0, \sigma = 1) = 0.8413447
$$
$$
P(-1 < x < 1|\mu = 0, \sigma = 1) = P(x < 1|\mu = 0, \sigma = 1) - P(x < -1|\mu = 0, \sigma = 1) = 0.841 - 0.158 = 0.682
$$

Wir spielen das Spiel beschrieben duch die Standardnormalverteilung 100 Mal.

```{r}
set.seed(123249)

## r(random/zufällig)norm(normal distribution)
norm_sim <- data.frame(
  ## Ziehe 100 Werte aus der Standardnormalverteilung
  x = rnorm(100, mean = 0, sd = 1)
) %>%
  mutate(
    ## &: logisches UND
    x_in_interval = x < 1 & x > -1
  )

## Code for illustration only
std_norm_plot + 
  geom_point(
    data = norm_sim, 
    aes(x = x, y = runif(100, -0.01, 0.01), colour = x_in_interval),
    size = 1,
    alpha = 1/2
  )
# +
#   geom_density(data = norm_sim, color = "steelblue2")
```

```{r}
table(norm_sim$x_in_interval)
```

<!-- ```{r} -->
<!-- d <- data.frame( -->
<!--   x = seq(-5, 5, length.out = 200) -->
<!-- ) %>% -->
<!--   mutate( -->
<!--     ## Dnorm computes the density  -->
<!--     y = dnorm(x, mean = 0, sd = 1) -->
<!--   ) -->

<!-- ## Code for illustration only -->
<!-- d %>%  -->
<!--   ggplot(aes(x = x)) + -->
<!--   # note this next line is the only difference in code from the last plot -->
<!--   geom_ribbon(data = d %>% filter(x > -1, x < 1), -->
<!--               aes(ymin = 0, ymax = y), fill = "gray") + -->
<!--   geom_line(aes(y = y)) + -->
<!--   annotate( -->
<!--     geom = "text",  -->
<!--     x = 0,  -->
<!--     y = 0.2,  -->
<!--     label = substitute( -->
<!--       "Area" %~~% p, -->
<!--       list( -->
<!--         p = round(pnorm(1) - pnorm(-1), 2) -->
<!--       ) -->
<!--     ) -->
<!--   ) + -->
<!--   labs( -->
<!--     x = "x", -->
<!--     y = "Normal density" -->
<!--   ) -->
<!-- ``` -->

```{r}
## Nur zur Illustration
d %>% 
  ggplot(aes(x = x)) +
  # note this next line is the only difference in code from the last plot
  geom_ribbon(data = d %>% filter(x > 1.96),
              aes(ymin = 0, ymax = y), fill = "gray") +
  geom_line(aes(y = y)) +
  annotate(
    geom = "text", 
    x = 3,
    y = 0.05, 
    label = substitute(
      "p" %~~% p,
      list(
        p = round(1 - pnorm(1.964), 3)
        )
      )
    ) +
  labs(
    x = "x",
    y = "Normal density"
  )
```
$$
P(x > 1.96|\mu = 0, \sigma = 1) = 1 - P(x < 1.96|\mu = 0, \sigma = 1) = 1 - pnorm(1.96, mean = 0, sd = 1)
$$
```{r}
1 - pnorm(1.96, mean = 0, sd = 1)
```


```{r}
d <- data.frame(
  x = seq(-5, 5, length.out = 200)
) %>%
  mutate(
    ## Dnorm computes the density 
    y = dnorm(x, mean = 0, sd = 1)
  )

d %>% 
  ggplot(aes(x = x)) +
  # note this next line is the only difference in code from the last plot
  geom_ribbon(data = d %>% filter(x > -1, x < 1),
              aes(ymin = 0, ymax = y), fill = "gray") +
  geom_line(aes(y = y)) +
  annotate(geom = "text", x = 0, y = 0.2, label = expression("p" %~~% "??")) +
  labs(x = "x",
       y = "Normal density")
```

## Samples simulation

Let us take the linear regression model and let us _assume_ that the random term $e_i$ follows a normal distribution with zero mean $\mu = 0$ and some standard deviation $\sigma$ (or equivalently variance $\sigma^2$).

$$
y_i = \alpha + \beta x_i + e_i\\
\text{Assume } e_i \sim N(0, \sigma^2)
$$


Assume that we know the function that describes the population of children is:

$$
\begin{align}
  (\#eq:reg-pop)
  y_i = 77.55 + 11.77 x_i + e_i
\end{align}
$$


We would like to study the way the estimates for $\alpha$ and $\beta$ vary from sample to sample. For that purpose we will generate $R = 2000$ samples from the population described by equation \@ref(eq:reg-pop). The we will estimate the regression model for each of these 2000 samples. What follows is a lot of rather technical details that
we need to generate the values for the samples and arrange these values in a way that is convenient for plotting and analysis.

We begin by introducing the `group_by` function and we'll use it to compute the sample group means for the two groups defined by `mom_hs`.

```{r}
## Do the same calculation of the group averages that
## we accomplished by splitting the data in two using `filter`.

kids %>% 
  group_by(mom_hs) %>%
  summarise(
    "Group size" = n(),
    "Average" = mean(kid_score)
  )
```

Next we calculate the _sample_ standard deviation of the IQ test scores (`kid_score`) and for now we will use this value for the standard deviation of the random terms $e_i$.

```{r}
## Estimate the standard deviation of the IQ scores (for all groups)
## so that we can base our simulation on a plausible value
sd(kids$kid_score)
```


Next we construct a data set using `expand_grid` to replicate the `mom_hs` column $R = 2000$ times.

```{r}
## Number of simulated samples

## Construct a data set with mom_hs repeated R = 2000 times
## Examine the contents of sim_df to see what expand_grid returns

sim_df <- expand_grid(
    R = 1:2000,
    mom_hs = kids$mom_hs
  )
```

After that we calculate the (simulated) IQ score for every child in every sample (a total of $2000 \times 434$ values) by using equation \ref{eq:pop-reg}. For the value of the random term we select a value from the normal distribution with mean 0 and standard deviation $\sigma = 20.41069$ (we will turn to the estimation of $\sigma$ later).

```{r}
sim_df <- sim_df %>%
  mutate(
    ## Compute a simulated IQ score for each kid according to our estimated regression equation
    ## rnorm adds a value selected at random from a normal distribution with mean = 0 and standard
    ## deviation (sigma) = 20.41 (that we estimated from the sample)
    e = rnorm(2000 * 434, mean = 0, sd = 19.85),
    kid_score = 77.54839 + 11.77 * mom_hs + e
  )
```

The last step completes the simulation of our 2000 samples and we can start estimating the regression model in each sample. For that we group the simulation data set `sim_df` by the simulation number (variable $R$) and run the regression model in every group. The `tidy` function serves to transform the output of `lm` into a format that can easily fit into a rectangular table.

```{r}
# tidy(lm(kid_score ~ mom_hs, data = kids))

sim_coeff <- sim_df %>%
  group_by(R) %>%
  ## The tidy function reformats the output of lm so that it can fit in a data frame
  do(tidy(lm(kid_score ~ mom_hs, data = .)))
```
E.g. `lm` result for the first sample

```{r}
fit <- lm(kid_score ~ mom_hs, data = sim_df %>% filter(R == 2))
fit
tidy(fit)
```



The data set `sim_coeff` now contains estimated coefficients ($\hat{\alpha}$ and $\hat{\beta}$) for every sample. To plot the distribution of $\hat{\beta}}$ we filter the data set so that we keep only the raw where `term == "mom_hs"` (i.e our estimates for $\beta$).

```{r}
slopes <- sim_coeff %>%
  filter(term == "mom_hs")

slopes %>%
  ggplot(aes(x = estimate)) + 
  geom_density()
```

```{r}
slopes %>%
  ggplot(aes(x = estimate)) + 
  geom_boxplot() +
  labs(
    x = "beta_hat",
    title = "Beta_hat distribution (over 2000 samples)"
  )
```
```{r}
summary(slopes$estimate)
```
```{r}
sd(slopes$estimate)
```


Here we use the `summarise_all` function to compute the mean for every variable in the simulation dataset, grouping it by term (remember, we have two terms in the output: the coefficients $\hat{\alpha}$ and $\hat{\beta}$).

```{r}
## Compute the mean of each column by coefficient
sim_coeff %>%
  group_by(term) %>%
  summarise_all(mean)
```

Next we would like to visualise the estimated regression lines for each sample. It is easier if we transform the dataset with the estimated coefficients for each sample are in separate columns. For now we are only interested in the `estimate` variable, so for the sake of simplicity we omit rest of the variables (this is the purpose of the `select` function). The we transform the data set from a long format.

```{r}
sim_coeff_wide <- sim_coeff %>%
  mutate(
    ## Rename the terms to get easier variable names
    term = ifelse(term == "(Intercept)", "alpha", "beta")
  ) %>%
  ## Keep only the R, term and estimate variables
  select(R, term, estimate) %>%
  ## Pivot the data set so that we have the estimated coefficients as columns
  pivot_wider(names_from = "term", values_from = "estimate")
```

Finally, we can plot the regression lines for each sample.

```{r}
sim_coeff_wide %>%
  filter(R < 1000) %>%
  ggplot() + 
    geom_abline(aes(intercept = alpha, slope = beta, group = R), alpha = 0.1, size = 1 / 5) + 
    ## Set the limits of x-axis
    xlim(c(0, 1)) +
    ## Set the limits of y-axis
    ylim(c(65, 95)) +
    labs(
      x = "Educational status of the mother 1: with HS, 0: without HS",
      y = "IQ test score"
    )
```

```{r}
fit <- lm(kid_score ~ mom_hs, data = kids)
fit
summary(fit)
```
- Estimate: $\hat{\alpha}$, $\hat{\beta}$
- Standard error of the estimate is the standard deviation of the estimator for the coefficient.

```{r}
summary(slopes$estimate)
sd(slopes$estimate)
```

```{r}
## Standard deviation
sd(c(1, 2, 3, 4))
sd(c(1, 1, 1, 3))
sd(c(1, 1, 1, 1))
sd(11.771)
```


<!-- Plot the distributions of scores for each simulated sample -->
<!-- ```{r} -->
<!-- sim_df %>% -->
<!--   filter(R < 50) %>% -->
<!--   ggplot( -->
<!--     aes( -->
<!--       x = kid_score,  -->
<!--       group = interaction(R, mom_hs), -->
<!--       colour = factor(mom_hs) -->
<!--       ) -->
<!--     ) + -->
<!--   geom_density( -->
<!--     size = 1/5 -->
<!--   ) -->
<!-- ``` -->
